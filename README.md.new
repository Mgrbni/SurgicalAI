# SurgicalAI - Advanced Skin Lesion Analysis Pipeline

An advanced AI-powered system for skin lesion analysis combining computer vision, Grad-CAM visualization, and vision-language models for enhanced diagnostic support.

## 🚀 New Features

### 1. Absolute Heatmap Alignment
- **Precise Grad-CAM mapping**: No drift or scaling bugs
- **Transform pipeline**: Centralized preprocessing with exact inverse transforms 
- **ROI-locked overlays**: Dual artifacts (full image + zoomed ROI)
- **Sub-pixel accuracy**: <1px mean error in coordinate mapping

### 2. Vision-LLM Observer  
- **Multi-provider support**: OpenAI GPT-4V and Anthropic Claude Vision
- **Structured analysis**: JSON-only responses with clinical descriptors
- **ABCD assessment**: Automated asymmetry, border, color, diameter evaluation
- **Clinical vocabulary**: Seborrheic keratosis descriptors ("stuck-on", "waxy", etc.)

### 3. Neuro-Symbolic Fusion
- **CNN + VLM integration**: Weighted combination of neural and symbolic analysis
- **Descriptor boosting**: SK probability increases when visual cues match
- **Uncertainty detection**: Automatic tie-breaking for close predictions  
- **Explainable decisions**: Clear notes on fusion reasoning

### 4. Enhanced Reporting
- **Dual overlays**: High-resolution ROI + full image context
- **Professional annotations**: Contours, crosshairs, surgical planning overlays
- **Comprehensive PDFs**: VLM observations, fusion notes, accuracy metrics
- **Surgical planning**: RSTL lines, flap designs, danger zones

## 🔧 Installation

```bash
# Clone repository
git clone https://github.com/Mgrbni/SurgicalAI.git
cd SurgicalAI

# Install dependencies  
pip install -r requirements.txt

# Set up environment variables for VLM providers
export VLM_PROVIDER=openai  # or anthropic
export OPENAI_API_KEY=your_key_here
# export ANTHROPIC_API_KEY=your_key_here
```

## 📋 Usage

### Quick Demo
```bash
# Run with default sample image
make demo

# Or specify custom image
python -m surgicalai_demo.pipeline --image data/samples/face.jpg --out runs/demo

# View results
open runs/demo/report.pdf
```

### Advanced Usage
```bash
# Enable Vision-LLM fusion (requires API key)
VLM_PROVIDER=openai python -m surgicalai_demo.pipeline \
  --image data/samples/lesion.jpg \
  --out runs/advanced_analysis

# Test coordinate mapping accuracy
python -m surgicalai_demo.transforms

# Run unit tests for accuracy verification  
python -m pytest tests/test_transform_accuracy.py -v
```

## 🎯 Key Capabilities

### Grad-CAM Visualization
- **Layer targeting**: Configurable CNN layers (`layer4.2` default)
- **ROI detection**: Automatic lesion localization with morphological cleanup
- **Dual resolution**: Full image context + high-resolution ROI zoom
- **Perceptual colormaps**: Plasma/magma for clinical visualization

### Vision-Language Analysis
```python
from surgicalai_demo.vlm_observer import describe_lesion_roi

# Analyze lesion ROI with VLM
analysis = describe_lesion_roi(image_bytes)
print(f"Primary pattern: {analysis['primary_pattern']}")
print(f"Key descriptors: {analysis['descriptors']}")
print(f"Recommendation: {analysis['recommendation']}")
```

### Fusion System
```python
from surgicalai_demo.fusion import fuse_probs

# Combine CNN and VLM predictions
result = fuse_probs(cnn_probs, vlm_analysis)
print(f"Final top-3: {result['top3']}")
print(f"Fusion notes: {result['fusion_notes']}")
```

## ⚙️ Configuration

### settings.yaml
```yaml
# Heatmap & ROI settings
heatmap:
  target_layer: "layer4.2"
  roi_threshold: 0.35
  roi_out_size: 512
  alpha: 0.55
  contour_levels: [0.3, 0.5, 0.7]
  colormap: "plasma"

# Vision-LLM Fusion
fusion:
  use_vlm: true
  cnn_weight: 0.7
  vlm_weight: 0.3
  sk_descriptor_bonus: 0.15
  tie_margin: 0.06
  provider: "${VLM_PROVIDER:-openai}"
```

## 🧪 Testing & Validation

### Transform Accuracy Tests
```bash
# Verify coordinate mapping accuracy
python tests/test_transform_accuracy.py

# Expected results:
# ✅ Mean error: <1.0px  
# ✅ Accuracy: >80% within tolerance
# ✅ ROI alignment: No drift detected
```

### Fusion System Tests  
```bash
# Test descriptor-based boosting
pytest tests/test_transform_accuracy.py::TestFusionSystem::test_sk_descriptor_boost -v

# Verify probability normalization
pytest tests/test_transform_accuracy.py::TestFusionSystem::test_probability_normalization -v
```

## 📊 Example Output

### Analysis Report Structure
```
runs/demo_2025-01-11_15-30-45/
├── overlay_full.png          # Full image with heatmap
├── overlay_zoom.png           # High-res ROI overlay  
├── heatmap.png               # Pure activation map
├── report.pdf                # Comprehensive clinical report
├── ai_summary.json           # Complete analysis results
├── metrics.json              # ABCDE + accuracy metrics
├── plan.json                 # Surgical planning details
└── neighbors/                # Retrieved similar cases
```

### Sample Fusion Output
```json
{
  "final_probs": {
    "seborrheic_keratosis": 0.67,
    "melanoma": 0.18,
    "nevus": 0.12
  },
  "top3": [
    ["seborrheic_keratosis", 0.67],
    ["melanoma", 0.18], 
    ["nevus", 0.12]
  ],
  "gate": "GREEN — likely seborrheic keratosis, routine monitoring",
  "fusion_notes": "VLM assessment: Seborrheic Keratosis • Descriptor adjustments: SK boosted +0.15 (3 descriptors) • Final prediction: Seborrheic Keratosis (67.0%)"
}
```

## 🎨 Visual Examples

### ROI-Locked Overlays
- **Perfect alignment**: Heatmaps precisely track lesion boundaries
- **No scaling artifacts**: Sub-pixel coordinate mapping accuracy
- **Dual resolution**: Full context + diagnostic detail
- **Clinical annotations**: Contours at 0.3/0.5/0.7 activation levels

### Surgical Planning Overlays
- **RSTL visualization**: Relaxed skin tension lines  
- **Flap design hints**: Bilobed, rotation, advancement patterns
- **Danger zone marking**: Critical anatomical structures
- **Professional rendering**: Anti-aliased graphics with legends

## 🔬 Technical Details

### Transform Pipeline
1. **Preprocessing**: Aspect-ratio preserving resize → center crop → padding → normalization
2. **Metadata capture**: Exact transform parameters for inverse mapping
3. **Grad-CAM computation**: Model-space activation extraction
4. **Inverse warping**: Precise mapping back to original coordinates
5. **Validation**: Round-trip accuracy testing with synthetic grids

### Fusion Algorithm
1. **Probability normalization**: CNN and VLM outputs → [0,1] 
2. **Descriptor matching**: Rule-based adjustments for clinical features
3. **Weighted combination**: Configurable CNN/VLM contribution ratios
4. **Re-ranking**: Final probability ordering with uncertainty detection
5. **Gate logic**: Clinical decision support based on confidence and class

## 🌐 Web API (Original)

The system also includes a FastAPI web server for browser-based analysis:

```bash
# Start web server
python -m uvicorn server.http_api:app --reload --port 8000

# Open browser interface
open http://localhost:8000
```

### API Endpoints
- `GET /healthz` — Service health check
- `POST /api/infer` — Non-streaming analysis
- `POST /api/stream` — Streaming analysis for real-time UI
- `POST /api/analyze` — Advanced analysis with VLM fusion

## ⚠️ Important Notes

- **NOT FOR CLINICAL USE**: Research and demonstration purposes only
- **Requires API keys**: OpenAI or Anthropic for VLM functionality
- **Demo mode**: Uses synthetic CNN probabilities (replace with real model)
- **Accuracy testing**: Run transform tests before clinical deployment

## 🤝 Contributing

1. **Transform accuracy**: Maintain <1px mean error requirement
2. **Descriptor vocabulary**: Use standard dermatological terminology  
3. **Test coverage**: Include unit tests for new fusion rules
4. **Clinical validation**: Verify outputs with dermatology experts

## 📚 References

- **Grad-CAM**: Selvaraju et al. "Grad-CAM: Visual Explanations from Deep Networks"
- **Vision-Language Models**: GPT-4V, Claude Vision technical documentation
- **Dermatology**: ABCD criteria, dermoscopy terminology standards
- **Surgical Planning**: RSTL anatomy, flap design principles

---

**Developed by Dr. Mehdi Ghorbani** - Plastic, Reconstructive & Aesthetic Surgery — Photo-Only Surgical Planning

FastAPI server + web client for surgical planning using 2D photos only. Uses an AI-powered vision pipeline to analyze patient photos and provide surgical recommendations.

## Quickstart (Photo-Only)

```bash
python -m venv .venv && .venv\Scripts\activate    # Windows
python -m pip install -e .
python -m pip install fastapi uvicorn[standard] python-multipart
python -m uvicorn server.http_api:app --reload --port 8000
python -m http.server 5173 -d client
```

Open http://localhost:5173 to use the client UI, which communicates with the FastAPI server at http://localhost:8000.

## Installation

**Requires Python 3.8 or newer.**

Windows: [Download Python 3.10 or newer](https://www.python.org/downloads/windows/)

Linux/Mac: Install with pyenv (example for 3.11.9):
```bash
pyenv install 3.11.9
pyenv virtualenv 3.11.9 surgicalai-env
pyenv activate surgicalai-env
```

## Features

This version has been streamlined to work with 2D photos only:
- 3D mesh processing has been disabled (Open3D and trimesh dependencies removed)
- UI updated for photo-only workflow
- Server API simplified for photo upload and analysis
- Vision pipeline optimized for 2D image analysis

## API Endpoints

- GET /health — service health check
- GET /api/metadata — get facial subunits taxonomy
- POST /api/analyze — analyze a patient photo with metadata
- GET /api/artifact/{path} — retrieve artifacts (images, reports, etc.)

## Example Workflow

1. Select a patient photo
2. Enter patient metadata (age, sex, site, etc.)
3. Submit for analysis
4. View results including:
   - Classification probabilities
   - Decision gate (proceed/defer)
   - Flap suggestions
   - Risk notes
   - Visualization overlays
   - Downloadable PDF report

## Development

The application is structured as:
- `server/` - FastAPI backend
- `client/` - HTML/JS/CSS frontend
- `src/surgicalai/` - Core Python package
- `data/` - Sample images for testing
- `runs/` - Output directory for analysis results
